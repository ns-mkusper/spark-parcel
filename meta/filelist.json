{
package
JOBNAME:generic-parcel-v2-rhel64-6-0:RELEASE_CODENAME::ArtifactType:package:Size:4508:BaseName:spark-worker-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm:FullName:/data/jenkins/workspace/generic-parcel-v2-rhel64-6-0/CDH5.7.0-Packaging-Parcel-2016-03-23_12-49-03/packages/binary/rpm_rhel6-cdh5.7.0_x86_64/spark-worker-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm
  , "spark-worker" : {
    "name": "spark-worker",
    "version": "1.6.0+cdh5.7.0+180",
    "files" : {
      "etc/rc.d/init.d/spark-worker" : {}
    }
  }
package
JOBNAME:generic-parcel-v2-rhel64-6-0:RELEASE_CODENAME::ArtifactType:package:Size:689336:BaseName:spark-python-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm:FullName:/data/jenkins/workspace/generic-parcel-v2-rhel64-6-0/CDH5.7.0-Packaging-Parcel-2016-03-23_12-49-03/packages/binary/rpm_rhel6-cdh5.7.0_x86_64/spark-python-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm
  , "spark-python" : {
    "name": "spark-python",
    "version": "1.6.0+cdh5.7.0+180",
    "files" : {
      "bin/pyspark" : {},
      "lib/spark/bin/pyspark" : {},
      "lib/spark/python" : {},
      "lib/spark/python/.gitignore" : {},
      "lib/spark/python/docs" : {},
      "lib/spark/python/docs/Makefile" : {},
      "lib/spark/python/docs/_static" : {},
      "lib/spark/python/docs/_static/pyspark.css" : {},
      "lib/spark/python/docs/_static/pyspark.js" : {},
      "lib/spark/python/docs/_templates" : {},
      "lib/spark/python/docs/_templates/layout.html" : {},
      "lib/spark/python/docs/conf.py" : {},
      "lib/spark/python/docs/epytext.py" : {},
      "lib/spark/python/docs/index.rst" : {},
      "lib/spark/python/docs/make.bat" : {},
      "lib/spark/python/docs/make2.bat" : {},
      "lib/spark/python/docs/pyspark.ml.rst" : {},
      "lib/spark/python/docs/pyspark.mllib.rst" : {},
      "lib/spark/python/docs/pyspark.rst" : {},
      "lib/spark/python/docs/pyspark.sql.rst" : {},
      "lib/spark/python/docs/pyspark.streaming.rst" : {},
      "lib/spark/python/lib" : {},
      "lib/spark/python/lib/PY4J_LICENSE.txt" : {},
      "lib/spark/python/lib/py4j-0.9-src.zip" : {},
      "lib/spark/python/lib/pyspark.zip" : {},
      "lib/spark/python/pyspark" : {},
      "lib/spark/python/pyspark/__init__.py" : {},
      "lib/spark/python/pyspark/accumulators.py" : {},
      "lib/spark/python/pyspark/broadcast.py" : {},
      "lib/spark/python/pyspark/cloudpickle.py" : {},
      "lib/spark/python/pyspark/conf.py" : {},
      "lib/spark/python/pyspark/context.py" : {},
      "lib/spark/python/pyspark/daemon.py" : {},
      "lib/spark/python/pyspark/files.py" : {},
      "lib/spark/python/pyspark/heapq3.py" : {},
      "lib/spark/python/pyspark/java_gateway.py" : {},
      "lib/spark/python/pyspark/join.py" : {},
      "lib/spark/python/pyspark/ml" : {},
      "lib/spark/python/pyspark/ml/__init__.py" : {},
      "lib/spark/python/pyspark/ml/classification.py" : {},
      "lib/spark/python/pyspark/ml/clustering.py" : {},
      "lib/spark/python/pyspark/ml/evaluation.py" : {},
      "lib/spark/python/pyspark/ml/feature.py" : {},
      "lib/spark/python/pyspark/ml/param" : {},
      "lib/spark/python/pyspark/ml/param/__init__.py" : {},
      "lib/spark/python/pyspark/ml/param/_shared_params_code_gen.py" : {},
      "lib/spark/python/pyspark/ml/param/shared.py" : {},
      "lib/spark/python/pyspark/ml/pipeline.py" : {},
      "lib/spark/python/pyspark/ml/recommendation.py" : {},
      "lib/spark/python/pyspark/ml/regression.py" : {},
      "lib/spark/python/pyspark/ml/tests.py" : {},
      "lib/spark/python/pyspark/ml/tuning.py" : {},
      "lib/spark/python/pyspark/ml/util.py" : {},
      "lib/spark/python/pyspark/ml/wrapper.py" : {},
      "lib/spark/python/pyspark/mllib" : {},
      "lib/spark/python/pyspark/mllib/__init__.py" : {},
      "lib/spark/python/pyspark/mllib/classification.py" : {},
      "lib/spark/python/pyspark/mllib/clustering.py" : {},
      "lib/spark/python/pyspark/mllib/common.py" : {},
      "lib/spark/python/pyspark/mllib/evaluation.py" : {},
      "lib/spark/python/pyspark/mllib/feature.py" : {},
      "lib/spark/python/pyspark/mllib/fpm.py" : {},
      "lib/spark/python/pyspark/mllib/linalg" : {},
      "lib/spark/python/pyspark/mllib/linalg/__init__.py" : {},
      "lib/spark/python/pyspark/mllib/linalg/distributed.py" : {},
      "lib/spark/python/pyspark/mllib/random.py" : {},
      "lib/spark/python/pyspark/mllib/recommendation.py" : {},
      "lib/spark/python/pyspark/mllib/regression.py" : {},
      "lib/spark/python/pyspark/mllib/stat" : {},
      "lib/spark/python/pyspark/mllib/stat/KernelDensity.py" : {},
      "lib/spark/python/pyspark/mllib/stat/__init__.py" : {},
      "lib/spark/python/pyspark/mllib/stat/_statistics.py" : {},
      "lib/spark/python/pyspark/mllib/stat/distribution.py" : {},
      "lib/spark/python/pyspark/mllib/stat/test.py" : {},
      "lib/spark/python/pyspark/mllib/tests.py" : {},
      "lib/spark/python/pyspark/mllib/tree.py" : {},
      "lib/spark/python/pyspark/mllib/util.py" : {},
      "lib/spark/python/pyspark/profiler.py" : {},
      "lib/spark/python/pyspark/rdd.py" : {},
      "lib/spark/python/pyspark/rddsampler.py" : {},
      "lib/spark/python/pyspark/resultiterable.py" : {},
      "lib/spark/python/pyspark/serializers.py" : {},
      "lib/spark/python/pyspark/shell.py" : {},
      "lib/spark/python/pyspark/shuffle.py" : {},
      "lib/spark/python/pyspark/sql" : {},
      "lib/spark/python/pyspark/sql/__init__.py" : {},
      "lib/spark/python/pyspark/sql/column.py" : {},
      "lib/spark/python/pyspark/sql/context.py" : {},
      "lib/spark/python/pyspark/sql/dataframe.py" : {},
      "lib/spark/python/pyspark/sql/functions.py" : {},
      "lib/spark/python/pyspark/sql/group.py" : {},
      "lib/spark/python/pyspark/sql/readwriter.py" : {},
      "lib/spark/python/pyspark/sql/tests.py" : {},
      "lib/spark/python/pyspark/sql/types.py" : {},
      "lib/spark/python/pyspark/sql/utils.py" : {},
      "lib/spark/python/pyspark/sql/window.py" : {},
      "lib/spark/python/pyspark/statcounter.py" : {},
      "lib/spark/python/pyspark/status.py" : {},
      "lib/spark/python/pyspark/storagelevel.py" : {},
      "lib/spark/python/pyspark/streaming" : {},
      "lib/spark/python/pyspark/streaming/__init__.py" : {},
      "lib/spark/python/pyspark/streaming/context.py" : {},
      "lib/spark/python/pyspark/streaming/dstream.py" : {},
      "lib/spark/python/pyspark/streaming/flume.py" : {},
      "lib/spark/python/pyspark/streaming/kafka.py" : {},
      "lib/spark/python/pyspark/streaming/kinesis.py" : {},
      "lib/spark/python/pyspark/streaming/listener.py" : {},
      "lib/spark/python/pyspark/streaming/mqtt.py" : {},
      "lib/spark/python/pyspark/streaming/tests.py" : {},
      "lib/spark/python/pyspark/streaming/util.py" : {},
      "lib/spark/python/pyspark/tests.py" : {},
      "lib/spark/python/pyspark/traceback_utils.py" : {},
      "lib/spark/python/pyspark/worker.py" : {},
      "lib/spark/python/run-tests" : {},
      "lib/spark/python/run-tests.py" : {},
      "lib/spark/python/test_support" : {},
      "lib/spark/python/test_support/SimpleHTTPServer.py" : {},
      "lib/spark/python/test_support/hello.txt" : {},
      "lib/spark/python/test_support/sql" : {},
      "lib/spark/python/test_support/sql/orc_partitioned" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/_SUCCESS" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=0" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=0/c=0" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=1" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=1/c=1" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc" : {},
      "lib/spark/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/_SUCCESS" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/_common_metadata" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/_metadata" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2014" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2014/month=9" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=9" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc" : {},
      "lib/spark/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet" : {},
      "lib/spark/python/test_support/sql/people.json" : {},
      "lib/spark/python/test_support/sql/people1.json" : {},
      "lib/spark/python/test_support/sql/text-test.txt" : {},
      "lib/spark/python/test_support/userlib-0.1.zip" : {},
      "lib/spark/python/test_support/userlibrary.py" : {}
    }
  }
package
JOBNAME:generic-parcel-v2-rhel64-6-0:RELEASE_CODENAME::ArtifactType:package:Size:4456:BaseName:spark-master-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm:FullName:/data/jenkins/workspace/generic-parcel-v2-rhel64-6-0/CDH5.7.0-Packaging-Parcel-2016-03-23_12-49-03/packages/binary/rpm_rhel6-cdh5.7.0_x86_64/spark-master-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm
  , "spark-master" : {
    "name": "spark-master",
    "version": "1.6.0+cdh5.7.0+180",
    "files" : {
      "etc/rc.d/init.d/spark-master" : {}
    }
  }
package
JOBNAME:generic-parcel-v2-rhel64-6-0:RELEASE_CODENAME::ArtifactType:package:Size:4632:BaseName:spark-history-server-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm:FullName:/data/jenkins/workspace/generic-parcel-v2-rhel64-6-0/CDH5.7.0-Packaging-Parcel-2016-03-23_12-49-03/packages/binary/rpm_rhel6-cdh5.7.0_x86_64/spark-history-server-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm
  , "spark-history-server" : {
    "name": "spark-history-server",
    "version": "1.6.0+cdh5.7.0+180",
    "files" : {
      "etc/rc.d/init.d/spark-history-server" : {}
    }
  }
package
JOBNAME:generic-parcel-v2-rhel64-6-0:RELEASE_CODENAME::ArtifactType:package:Size:117297744:BaseName:spark-core-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm:FullName:/data/jenkins/workspace/generic-parcel-v2-rhel64-6-0/CDH5.7.0-Packaging-Parcel-2016-03-23_12-49-03/packages/binary/rpm_rhel6-cdh5.7.0_x86_64/spark-core-1.6.0+cdh5.7.0+180-1.cdh5.7.0.p0.84.el6.noarch.rpm
  , "spark-core" : {
    "name": "spark-core",
    "version": "1.6.0+cdh5.7.0+180",
    "files" : {
      "etc/default/spark" : {},
      "etc/spark" : {},
      "etc/spark/conf.dist" : {},
      "etc/spark/conf.dist/docker.properties.template" : {},
      "etc/spark/conf.dist/fairscheduler.xml.template" : {},
      "etc/spark/conf.dist/log4j.properties.template" : {},
      "etc/spark/conf.dist/metrics.properties.template" : {},
      "etc/spark/conf.dist/slaves.template" : {},
      "etc/spark/conf.dist/spark-defaults.conf" : {},
      "etc/spark/conf.dist/spark-defaults.conf.template" : {},
      "etc/spark/conf.dist/spark-env.sh" : {},
      "etc/spark/conf.dist/spark-env.sh.template" : {},
      "bin/spark-executor" : {},
      "bin/spark-shell" : {},
      "bin/spark-submit" : {},
      "lib/hadoop-yarn" : {},
      "lib/hadoop-yarn/lib" : {},
      "lib/hadoop-yarn/lib/spark-1.6.0-cdh5.7.0-yarn-shuffle.jar" : {},
      "lib/hadoop-yarn/lib/spark-yarn-shuffle.jar" : {},
      "lib/spark" : {},
      "lib/spark/LICENSE" : {},
      "lib/spark/NOTICE" : {},
      "lib/spark/RELEASE" : {},
      "lib/spark/assembly" : {},
      "lib/spark/assembly/lib" : {},
      "lib/spark/assembly/lib/spark-assembly-1.6.0-cdh5.7.0-hadoop2.6.0-cdh5.7.0.jar" : {},
      "lib/spark/assembly/lib/spark-assembly.jar" : {},
      "lib/spark/bin" : {},
      "lib/spark/bin/load-spark-env.sh" : {},
      "lib/spark/bin/run-example" : {},
      "lib/spark/bin/spark-class" : {},
      "lib/spark/bin/spark-shell" : {},
      "lib/spark/bin/spark-submit" : {},
      "lib/spark/cloudera" : {},
      "lib/spark/cloudera/cdh_version.properties" : {},
      "lib/spark/conf" : {},
      "lib/spark/examples" : {},
      "lib/spark/examples/lib" : {},
      "lib/spark/examples/lib/python.tar.gz" : {},
      "lib/spark/examples/lib/spark-examples-1.6.0-cdh5.7.0-hadoop2.6.0-cdh5.7.0.jar" : {},
      "lib/spark/lib" : {},
      "lib/spark/lib/python.tar.gz" : {},
      "lib/spark/lib/spark-assembly-1.6.0-cdh5.7.0-hadoop2.6.0-cdh5.7.0.jar" : {},
      "lib/spark/lib/spark-assembly.jar" : {},
      "lib/spark/lib/spark-examples-1.6.0-cdh5.7.0-hadoop2.6.0-cdh5.7.0.jar" : {},
      "lib/spark/lib/spark-examples.jar" : {},
      "lib/spark/sbin" : {},
      "lib/spark/sbin/slaves.sh" : {},
      "lib/spark/sbin/spark-config.sh" : {},
      "lib/spark/sbin/spark-daemon.sh" : {},
      "lib/spark/sbin/spark-daemons.sh" : {},
      "lib/spark/sbin/start-all.sh" : {},
      "lib/spark/sbin/start-history-server.sh" : {},
      "lib/spark/sbin/start-master.sh" : {},
      "lib/spark/sbin/start-mesos-dispatcher.sh" : {},
      "lib/spark/sbin/start-mesos-shuffle-service.sh" : {},
      "lib/spark/sbin/start-shuffle-service.sh" : {},
      "lib/spark/sbin/start-slave.sh" : {},
      "lib/spark/sbin/start-slaves.sh" : {},
      "lib/spark/sbin/stop-all.sh" : {},
      "lib/spark/sbin/stop-history-server.sh" : {},
      "lib/spark/sbin/stop-master.sh" : {},
      "lib/spark/sbin/stop-mesos-dispatcher.sh" : {},
      "lib/spark/sbin/stop-mesos-shuffle-service.sh" : {},
      "lib/spark/sbin/stop-shuffle-service.sh" : {},
      "lib/spark/sbin/stop-slave.sh" : {},
      "lib/spark/sbin/stop-slaves.sh" : {},
      "lib/spark/work" : {},
      "share/doc/spark-1.6.0+cdh5.7.0+180" : {}
    }
  }
}
